# chapter01. Review Neural Network

- 이 책은 전편에 이어 딥러닝의 가능성을 한층 더 깊이 탐험할 것입니다.

  - 물론, 전편과 동일하게 라이브러리나 프레임워크 는 최대한 사용하지 않고 밑바닥부터 구현할 것입니다.

- 이번 장에서는 신경망을 복습합니다. 전편의 내용을 요약한 장이기도 합니다.

  - 다만 차이점은 효율 향상을 위해 전편의 구현 규칙을 일부 변경했습니다.

## 1.1 수학과 python 복습

- 먼저 수학, 즉 신경망 계산에 필요한 '벡터'나 '행렬'에 대해 복습하겠습니다. 또, 신경망을 원할히 구현하기 위한 python, 특히 numpy 코드도 되새겨볼 것입니다.

### 1.1.1 벡터와 행렬

- 신경망은 벡터와 행렬(또는 텐서)가 도처에서 등장하니 이를 가볍게 정리하겠습니다.

  - 벡터는 크기와 방향을 가진 양으로 숫자가 일렬로 늘어선 집합으로 표현할 수 있습니다.

    - 즉, 파이썬에서는 1차원 배열로 취급할 수 있습니다.

  - 반면에 행렬을 숫자가 2차원 형태로 늘어선 것으로 다음과 같은 차이를 가집니다.

  <img src="README.assets/fig 1-1.png" alt="fig 1-1" style="zoom:50%;" />

- 이처럼 벡터는 1차원, 행렬은 2차원 배열로 표현할 수 있으며 행렬의 가로를 행, 세로를 열이라고 합니다.

#### Note

> 벡터와 행렬을 확장해 숫자 집합을 N차원으로 표현한 것은 일반적으로 텐서라고 합니다

- 벡터는 단순한 개념이지만 이를 표현하는 방법이 행과 열, 두 가지로 나뉩니다.

<img src="README.assets/fig 1-2.png" alt="fig 1-2" style="zoom:50%;" />

- 수학과 딥러닝 등 많은 분야에서 '열벡터' 방식을 선호하지만, 이 책에서는 구현의 편의를 고려해 '행벡터'로 다루겠습니다.

  - 또한, 수식에서 벡터와 행렬은 **x**나 **W**처럼 굵게 강조하여 단일 원소로 구성된 스칼라와 구분하겠습니다.

#### Warning

> python으로 벡터를 행벡터로 구현할 때, 벡터를 가로 방향 행렬로 변환해 사용하면 보다 명확해집니다.
>
> 예를 들어 원소 수가 N개인 벡터는 1 \* N 형상의 행렬로 처리합니다.

- 그럼 python을 통해 벡터와 행렬에 대해 알아보겠습니다.

```python
import numpy as np

x = np.array([1, 2, 3])
print('class:', x.__class__)
print('shape:', x.shape)
print('dimension:', x.dim)

W = np.array([[1, 2, 3], [4, 5, 6]])
print('shape:', W.shape)
print('dimension:', W.dim)
```

- 이처럼 벡터와 행렬 모두 `np.array()`로 생성할 수 있습니다.

  - 이 메서드는 `np.ndarray` 클래스를 생성하며 이 클래스에는 다양한 메서드와 인스턴스 변수가 내장되어 있습니다.

    - 앞선 예제는 인스턴스 변수 중 `shape`와 `dim`을 사용했고 각각 다차원 배열의 형상과 차원의 수를 의미합니다.

- 결과를 보면 x는 1차원 배열에 원소 수가 3개인 벡터이고 W는 2차원 배열에 2행 3열의 행렬임을 알 수 있습니다.

### 1.1.2 행렬의 원소별 연산

- 수의 집합을 벡터나 행렬로 표현했다면 이를 간단히 계산하는 과정은 다음과 같습니다. 우선 원소별 연산입니다.

```python
X = np.array([[1, 2, 3], [4, 5, 6]])
W = np.array([[2, 4, 6], [1, 3, 5]])
print(X + W)
print(X * W)
```

- 다차원 numpy의 더하기와 곱하기를 위와 같이 하면 피연산자인 다차원 배열들에서 서로 대응하는 원소끼리 독립적인 연산이 이루어집니다.

### 1.1.3 브로드캐스트

- numpy의 다차원 배열에서 형상이 다른 배열끼리도 연산할 수 있는데 이를 브로드캐스트라고 합니다.

```python
A = np.array([[1, 2], [3, 4]])
print(A * 10)
```

- 위 계산에서 2행 2열의 행렬에 스칼라 10을 곱하면 스칼라 값이 동일한 크기의 행렬로 확장된 후 원소별 연산을 수행합니다.

<img src="README.assets/fig 1-3.png" alt="fig 1-3" style="zoom:50%;" />

- 또 다른 예시는 다음과 같습니다.

```python
A = np.array([[1, 2], [3, 4]])
b = np.array([10, 20])
print(A * b)
```

- 위 계산도 1차원 배열이 2차원 배열로 형상이 같아지도록 확장된 수 이를 계산합니다.

<img src="README.assets/fig 1-4.png" alt="fig 1-4" style="zoom:50%;" />

#### Warning

> numpy의 브로드캐스트가 효과적으로 동작하려면 다차원 배열의 형상이 몇 가지 규칙을 충족해야합니다.
>
> 자세한 내용은 문헌을 참고하세요.

### 1.1.4 벡터의 내적과 행렬의 곱

- 다음은 벡터의 내적과 행렬의 곱입니다. 우선 벡터의 내적은 다음과 같이 진행됩니다.

<img src="README.assets/e 1-1.png" alt="e 1-1" style="zoom:50%;" />

- 이처럼 2개의 벡터가 존재할 때 백터의 내적은 두 벡터에서 대응하는 원소들의 곱을 모두 더한 것과 같습니다.

#### Note

> 벡터의 내적은 직관적으로 '두 벡터가 얼마나 같은 방향을 향하고 있는가'를 의미합니다.
>
> 벡터의 길이가 1인 경우, 완전히 같은 방향을 향하는 두 벡터의 내적은 1이지만 반대를 향하는 두 벡터의 내적은 -1입니다.

- 계속해서 행렬의 곱은 다음과 같은 수서로 계산됩니다.

<img src="README.assets/fig 1-5.png" alt="fig 1-5" style="zoom:50%;" />

- 이처럼 행렬의 곱은 왼쪽 행렬의 행벡터와 오른쪽 행렬의 열벡터의 내적으로 계산하고 그 결과를 새로운 행렬의 대응하는 원소에 저장합니다.

  - 예를 들어 A의 1행과 B의 1열의 연산 결과는 새로운 행렬의 1행 1열의 원소입니다.

- 이들을 python으로 구현하는 방식은 `np.dot()`과 `np.matmul()`입니다.

```python
# inner calculation of vectors
a = np.array([1, 2, 3])
b = np.array([1, 2, 3])
print(np.dot(a, b))

# multiple of matrix
A = np.array([[1, 2], [3, 4]])
B = np.array([[1, 2], [3, 4]])
print(np.matmul(A, B))
```

- 사실 두 연산 모두 `np.dot()`을 사용할 수 있으나 가능하면 둘을 구분하여 코드의 논리와 의도를 명확히하는 것이 좋습니다.

  - `np.dot()`과 `np.matmul()` 외에도 행렬 계산을 도와주는 편의 메서드는 많습니다. 이를 적절히 활용한다면 신경망 구현에 어려움이 없을 것입니다.

#### Note

> numpy를 익히는 가장 좋은 방법은 실제 코딩하며 연습하는 것이 제일입니다.
>
> numpy 경험을 쌓고 싶다면 '100 numpy exercises'를 추천합니다. 말 그대로 100개의 연습문제를 도전하며 실력을 쌓을 수 있습니다.

### 1.1.5 행렬 형상 확인

- 행렬이나 벡터를 사용해 계산할 때는 그 '형상'에 주의해야 합니다. 이는 행렬의 곱을 위한 것으로 다음처럼 '형상 확인'이 중요합니다.

<img src="README.assets/fig 1-6.png" alt="fig 1-6" style="zoom:50%;" />

- 위 그림은 (3, 2) 행렬 A와 (2, 4) 행렬 B를 곱해 (3, 4) 행렬 C를 만드는 예시로 이처럼 두 행렬의 대응하는 차원의 원소 수가 같아야 합니다.

  - 그래야 그 결과인 행렬의 형상은 피연산 행렬의 행의 수와 연산 행렬의 열의 수를 가지게 됩니다. 이게 '형상 확인'입니다.

#### Note

> 행렬의 곱 등 행렬 계산에 형상 확인을 해야만 신경망 구현을 부드럽게 진행할 수 있습니다.
