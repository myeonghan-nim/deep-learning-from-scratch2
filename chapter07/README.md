# chapter07. RNN을 사용한 문장 생성

5장과 6장에서 RNN과 LSTM의 구조와 구현을 자세하게 살펴봤습니다.
바야흐로 우리는 이 개념들을 구현 수준에서 이해하게 된 것입니다.
이번 장에서는 지금까지의 성과, RNN과 LSTM이 꽃을 피웁니다.
LSTM을 이용해 재미있는 애플리케이션을 구현해볼 것이기 때문입니다.

이번 장에서는 언어 모델을 사용해 '문장 생성'을 수행합니다.
구체적으로는 우선 말뭉치를 사용해 학습한 언어 모델을 이용하여 새로운 문장을 만들어냅니다
그런 다음 개선된 언어 모델을 이용하여 더 자연스러운 문장을 생성하는 모습을 선보이겠습니다.
여기까지 해보면 'AI로 글을 쓰게 한다'라는 개념을 간단하게라도 실감할 수 있을 것입니다.

여기서 멈추지 않고 seq2seq라는 새로운 구조의 신경망도 다룹니다.
seq2seq란 'from sequence to sequence', 즉 '시계열에서 시계열로'를 뜻하는 말로, 한 시계열 데이터를 다른 시계열 데이터로 변환하는 걸 말압니다.
이번 장에서는 RNN 두 개를 연결하는 아주 간단한 방법으로 seq2seq를 구현해볼 것입니다.
seq2seq는 기계 번역, 챗봇, 메일의 자동 답신 등 다양하게 응용될 수 있습니다.
간단하면서 영리하고 강력한 seq2seq를 이해하고 나면 딥러닝의 가능성이 더욱 크게 느껴질 것입니다!
